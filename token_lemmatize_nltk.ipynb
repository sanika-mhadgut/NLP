{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "token_lemmatize_nltk.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanika-mhadgut/NLP/blob/master/token_lemmatize_nltk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZylxBoaIO71X",
        "colab_type": "text"
      },
      "source": [
        "#Name : Sanika Mhadgut\n",
        "#Branch : Btech Data Science sem 6\n",
        "#Roll No: J031\n",
        "\n",
        "Word tokenization, Stopwords removal, Lemmatization.\n",
        "\n",
        "\n",
        "Fetch column: “reviews” because we need only that column for extracting sentiments from customers\n",
        "\n",
        "\n",
        "Remove header and convert all the data into lowercase for easy processing.\n",
        "\n",
        "\n",
        "Text data can be split into sentences and this process is called sentence tokenization.\n",
        "\n",
        "\n",
        "Now split each sentence into words, also called word tokenization.\n",
        "\n",
        "\n",
        "To move ahead first we will clean our data, here we’re gonna remove stopwords, punctuations and empty spaces.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihSynL88jL6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import string\n",
        "import re\n",
        "import nltk\n",
        "import spacy\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-CA7uPtjTIJ",
        "colab_type": "code",
        "outputId": "71e14584-def6-4fdf-bf57-69ead3112b4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zc4yL3sXjVfA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Office_Products_5.json.gz\"\n",
        "r = pd.read_json(url,lines=True)\n",
        "df1 = r.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XkdQjd7Pizn",
        "colab_type": "text"
      },
      "source": [
        "Lemmatization\n",
        "Stemming and Lemmatization are the basic text processing methods for English text. The goal of both of them is to reduce inflectional forms and sometimes derivationally related forms of a word to a common base form. I have skipped Stemming because it is not an efficient method as sometimes it produces words that are not even close to the actual word.\n",
        "def lemmatizationFunct(x):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fjWhzkBjVlO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lem  = WordNetLemmatizer()\n",
        "mwet = nltk.tokenize.MWETokenizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJa7UPkAjVnT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def nltkpipe(text):\n",
        "  wt_list = nltk.tokenize.word_tokenize(text)\n",
        "  mwe_list = mwet.tokenize(text.split())\n",
        "  tabb = dict(nltk.pos_tag(text.split()))\n",
        "  wordadj = ' '.join([word for word in tabb if tabb[word]=='JJ'])\n",
        "  mwelem = ' '.join([lem.lemmatize(word,'v') for word in mwe_list])\n",
        "  wtlem = ' '.join([lem.lemmatize(word,'v') for word in wt_list])\n",
        "  result = {'MWE':mwelem,'wtlem':wtlem,'word_adj':wordadj}\n",
        "  return  result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5rjjsRPjVpj",
        "colab_type": "code",
        "outputId": "c7d5e224-7747-4d6e-9de0-b5c088514927",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "nltkpipe(df1['reviewText'][0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MWE': \"I buy my first HP12C in about 1984 or so, and it serve me faithfully until 2002 when I lose it while travelling. I search for another one to replace it, but find one difficult to come by in my area. So, I decide to buy up and purchase an HP 49G. What a mistake! I know that many people view the HP 49G (now 49G+) as the flagship of the HP line, but for me that be a disaster.The 49G may be powerful, but use it be extremely counterintuitive...and the manual be sketchy at best. The 12C, on the other hand, do what I need in a way that make good sense to me.If you be look for a solid, reliable calculator, the HP12C may be for you. It's programmable. It do basic statistics well, and many business applications too. The manual make sense; you will be up and run in short order.I'm ready to set my 49G aside and move back to my old friend. I didn't even have to replace the batteries in well over a decade of use!HP 12C, I'm come home!\",\n",
              " 'word_adj': 'first difficult area. many disaster.The manual other good reliable you. basic short ready old use!HP',\n",
              " 'wtlem': \"I buy my first HP12C in about 1984 or so , and it serve me faithfully until 2002 when I lose it while travel . I search for another one to replace it , but find one difficult to come by in my area . So , I decide to buy up and purchase an HP 49G . What a mistake ! I know that many people view the HP 49G ( now 49G+ ) as the flagship of the HP line , but for me that be a disaster.The 49G may be powerful , but use it be extremely counterintuitive ... and the manual be sketchy at best . The 12C , on the other hand , do what I need in a way that make good sense to me.If you be look for a solid , reliable calculator , the HP12C may be for you . It 's programmable . It do basic statistics well , and many business applications too . The manual make sense ; you will be up and run in short order.I 'm ready to set my 49G aside and move back to my old friend . I do n't even have to replace the batteries in well over a decade of use ! HP 12C , I 'm come home !\"}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    }
  ]
}